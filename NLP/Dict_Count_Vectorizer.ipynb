{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "bow:단어의 순서 고려 x, 단어의 빈도수를 기반으로 만든 행렬\n",
    "1)단어 추출 -> 단어에 대해 정수 인덱스 설정\n",
    "2)단어의 등장 횟수를 저장한 벡터를 생성\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"정부가 .발표하는. 물가상승률과 .소비자가 느끼는 .물가상승률은 .다르다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) text에서 마침표 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "token = re.sub('\\.','',text)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['정부', '가', '발표', '하는', '물가상승률', '과', '소비자', '가', '느끼는', '물가상승률', '은', '다르다']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = okt.morphs(token) # 형태소 단위 tokenize\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {}  # Bow 지정할 딕셔너리, {정부 : 0, 가 :1 / 단어 : 인덱스 번호}\n",
    "bow = [] #{1,1 단어빈도수,단어빈도수..}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n",
      "[2, 3, 2, 2, 3, 2, 2, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "for v in token:\n",
    "    if v not in word2index.keys(): # 중복 단어는 indexing 하지 않음 \n",
    "        word2index[v] = len(word2index)\n",
    "        bow.insert(len(word2index)-1,1) # 딕셔너리 특정위치에 삽입하는 insert \n",
    "        # insert(0,1) >> 0번쨰에 1을 너어라 \n",
    "    else:\n",
    "        # 중복 단어면 index는 그대로, 단어빈도수만 1 증가\n",
    "        idx = word2index.get(v) # get : key값만 리턴\n",
    "        bow[idx] = bow[idx]+1\n",
    "print(word2index)\n",
    "print(bow)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체문서 (n개 Doc) = [d1,d2, ... ,dn]\n",
    "# 단어집합 (m개 word) = {t1,t2, ... ,tm }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DicVectorizer : BoW 생성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bow 만드는 class\n",
    "from sklearn.feature_extraction import DictVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': 1, 'b': 2}, {'b': 3, 'c': 1}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = DictVectorizer(sparse=False) # True : 텍스트데이터 압축해서 bow 생성 (메모리 효율)\n",
    "d = [{'a':1,'b':2}, {'b':3,'c':1}] # [문서1, 문서2] {단어1:빈도수, 단어2:빈도수}\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 0.]\n",
      " [0. 3. 1.]]\n",
      "['a', 'b', 'c']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 5.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(v.fit_transform(d)) # bow 생성 (a,b,c로 구성)\n",
    "print(v.feature_names_)\n",
    "\n",
    "v.transform({'c':5, 'd':2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer\n",
    "- Doc를 Token 변환 후 BoW 벡터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 문서 -> 토큰 변환 2) 토큰의 빈도수 3) bow 벡터 생성\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=['This is the first document.',\n",
    "    'This is the second second document.',\n",
    "    'And the third one.',\n",
    "    'Is this the first document?',\n",
    "    'The last document?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 9,\n",
       " 'is': 3,\n",
       " 'the': 7,\n",
       " 'first': 2,\n",
       " 'document': 1,\n",
       " 'second': 6,\n",
       " 'and': 0,\n",
       " 'third': 8,\n",
       " 'one': 5,\n",
       " 'last': 4}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = CountVectorizer()\n",
    "v.fit(corpus)\n",
    "v.vocabulary_ # {word : index 변환}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 0, 2, 1, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0, 0, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 0, 1, 0, 0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.transform(corpus).toarray()\n",
    "# this is the first documnet\n",
    "# ARRAY 속 list는 각각의 doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 2, 3, 1, 1, 2, 5, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.transform(corpus).toarray().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'this': 3, 'is': 2, 'first': 1, 'document': 0},\n",
       " {'and', 'last', 'one', 'second', 'the', 'third'})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = CountVectorizer(min_df=2, max_df=4) # 단어들이 몇개의 문서에서 등장하는지\n",
    "v.fit(corpus)\n",
    "v.vocabulary_, v.stop_words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this is': 12,\n",
       " 'is the': 2,\n",
       " 'the first': 7,\n",
       " 'first document': 1,\n",
       " 'the second': 9,\n",
       " 'second second': 6,\n",
       " 'second document': 5,\n",
       " 'and the': 0,\n",
       " 'the third': 10,\n",
       " 'third one': 11,\n",
       " 'is this': 3,\n",
       " 'this the': 13,\n",
       " 'the last': 8,\n",
       " 'last document': 4}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 두 단어가 1개의 단어로 사용\n",
    "# ngram_range=(n,m) 의미? 최소 n개 최대m개의 단어를 묶어서 1개의 단어로 취급\n",
    "v= CountVectorizer(ngram_range=(2,2)) # 최소:2, 최대:2 => n값이 2인 gram = 2gram (bigram)\n",
    "v.fit(corpus)\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first': 1, 'document': 0, 'second': 4, 'third': 5, 'one': 3, 'last': 2}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = CountVectorizer(stop_words=['and','is','the','this'])\n",
    "v.fit(corpus)\n",
    "v.vocabulary_ # stop words로 빠진 나머지가 vocabulary로 들어옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 2, 'the': 0, 'third': 1}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ngram_range(1,2)\n",
    "v = CountVectorizer(token_pattern ='t\\w+') # t로 시작하는것만 bow로\n",
    "# \\w+ 단어 단위\n",
    "# \\w 문자 단위\n",
    "v.fit(corpus)\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 3, 'the': 0, 'this the': 4, 'third': 2, 'the third': 1}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ngram_range(1,2) t로 시작하는것중 최소1 최대 2\n",
    "v = CountVectorizer(ngram_range=(1,2),token_pattern='t\\w+') # t로시작하는 \n",
    "v.fit(corpus)\n",
    "v.vocabulary_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'t': 16,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 's': 15,\n",
       " ' ': 0,\n",
       " 'e': 6,\n",
       " 'f': 7,\n",
       " 'r': 14,\n",
       " 'd': 5,\n",
       " 'o': 13,\n",
       " 'c': 4,\n",
       " 'u': 17,\n",
       " 'm': 11,\n",
       " 'n': 12,\n",
       " '.': 1,\n",
       " 'a': 3,\n",
       " '?': 2,\n",
       " 'l': 10}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = CountVectorizer(analyzer='char') # 문자단위로 생성\n",
    "v.fit(corpus)\n",
    "v.vocabulary_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': 0, 'second': 1}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = CountVectorizer(stop_words='english')\n",
    "v.fit(corpus)\n",
    "v.vocabulary_ # stop words로빠진나머지가 vocabulary로들어옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'first': 1, 'document': 0, 'second': 4, 'third': 5, 'one': 3, 'last': 2}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=CountVectorizer(stop_words=['and','is','the','this'])\n",
    "v.fit(corpus)\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 9,\n",
       " 'is': 3,\n",
       " 'the': 7,\n",
       " 'first': 2,\n",
       " 'document': 1,\n",
       " 'second': 6,\n",
       " 'and': 0,\n",
       " 'third': 8,\n",
       " 'one': 5,\n",
       " 'last': 4}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v=CountVectorizer()\n",
    "v.fit(corpus)\n",
    "v.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- trasnform() : Corpus로 fitting 된 BoW를 바탕으올 Array 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 0, 0, 1, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운문서 입력 -> BoW로변환\n",
    "'This is the second document'\n",
    "v.transform(['This is the second document']) # sparse matrix\n",
    "v.transform(['This is the second document']).toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
